{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading translation model and tokenizer...\n",
      "Loading QA model and tokenizer...\n",
      "Downloading MACULA Greek data...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
    "import gradio as gr\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Load the translation model and tokenizer\n",
    "print('Loading translation model and tokenizer...')\n",
    "translation_model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "translation_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    translation_model_name)\n",
    "translation_tokenizer = AutoTokenizer.from_pretrained(translation_model_name)\n",
    "\n",
    "# Instantiate the translation pipelines\n",
    "deu_translator = pipeline('translation', model=translation_model,\n",
    "                          tokenizer=translation_tokenizer, src_lang=\"en\", tgt_lang=\"de\")\n",
    "spa_translator = pipeline('translation', model=translation_model,\n",
    "                          tokenizer=translation_tokenizer, src_lang=\"en\", tgt_lang=\"es\")\n",
    "fra_translator = pipeline('translation', model=translation_model,\n",
    "                          tokenizer=translation_tokenizer, src_lang=\"en\", tgt_lang=\"fr\")\n",
    "\n",
    "# Load the model and tokenizer\n",
    "print('Loading QA model and tokenizer...')\n",
    "# model_name = \"deepset/roberta-base-squad2\"\n",
    "model_name = \"deepset/bert-large-uncased-whole-word-masking-squad2\"\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "qa_pipeline = pipeline('question-answering',\n",
    "                       model=model_name, tokenizer=model_name)\n",
    "\n",
    "\n",
    "# Set up MACULA data as pandas dataframe\n",
    "print('Downloading MACULA Greek data...')\n",
    "\n",
    "\n",
    "def download_file(url, file_name):\n",
    "    response = requests.get(url)\n",
    "    with open(file_name, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "\n",
    "file1_url = 'https://raw.githubusercontent.com/Clear-Bible/macula-greek/main/Nestle1904/TSV/macula-greek.tsv'\n",
    "file2_url = 'https://raw.githubusercontent.com/Clear-Bible/macula-greek/main/sources/MARBLE/SDBG/marble-domain-label-mapping.json'\n",
    "file1_name = 'macula-greek.tsv'\n",
    "file2_name = 'marble-domain-label-mapping.json'\n",
    "\n",
    "if file1_name not in os.listdir():\n",
    "    download_file(file1_url, file1_name)\n",
    "\n",
    "if file2_name not in os.listdir():\n",
    "    download_file(file2_url, file2_name)\n",
    "\n",
    "# Import Macula Greek data\n",
    "mg = pd.read_csv('macula-greek.tsv', index_col='xml:id', sep='\\t',\n",
    "                 header=0, converters={'*': str}).fillna('missing')\n",
    "# mg['domain'] = mg['domain'].astype(str).fillna('missing')\n",
    "\n",
    "# Extract book, chapter, and verse into separate columns\n",
    "mg[['book', 'chapter', 'verse']] = mg['ref'].str.extract(\n",
    "    r'(\\d?[A-Z]+)\\s(\\d+):(\\d+)')\n",
    "\n",
    "# Add columns for book + chapter, and book + chapter + verse for easier grouping\n",
    "mg['book_chapter'] = mg['book'] + ' ' + mg['chapter'].astype(str)\n",
    "mg['book_chapter_verse'] = mg['book_chapter'] + ':' + mg['verse'].astype(str)\n",
    "\n",
    "# Import domain-label mapping\n",
    "\n",
    "# Open the JSON file\n",
    "with open('marble-domain-label-mapping.json', 'r') as f:\n",
    "\n",
    "    # Load the contents of the file as a dictionary\n",
    "    domain_labels = json.load(f)\n",
    "\n",
    "domain_labels['missing'] = 'no domain'\n",
    "domain_labels['nan'] = 'no domain'\n",
    "\n",
    "# Use domain labels to create a new column\n",
    "\n",
    "\n",
    "def get_domain_label(domain_string_number):\n",
    "    labels = [domain_labels[label]\n",
    "              for label in domain_string_number.split(' ')]\n",
    "    return labels\n",
    "\n",
    "\n",
    "mg['domain_label'] = mg['domain'].apply(get_domain_label)\n",
    "\n",
    "# to get data for a specific word, use the following code:\n",
    "# mg.loc['n40001001002'].to_dict() where n40001001002 is the word ID\n",
    "\n",
    "# Create a dictionary with attribute descriptions\n",
    "attribute_descriptions = {\n",
    "    \"after\": \"Encodes the following character, including a blank space.\",\n",
    "    \"articular\": \"'true' if the word has an article (i.e., modified by the word 'the').\",\n",
    "    \"case\": \"Grammatical case: nominative, genitive, dative, accusative, or vocative\",\n",
    "    \"class\": \"On words, the class is the word's part of speech\",\n",
    "    \"cltype\": \"Explicitly marks Verbless Clauses, Verb Elided Clauses, and Minor Clauses\",\n",
    "    \"degree\": \"A derivative lexical category, indicating the degree of the adjective\",\n",
    "    \"discontinuous\": \"'true' if the word is discontinuous with respect to sentence order due to reordering in the syntax tree\",\n",
    "    \"domain\": \"Semantic domain information from the Semantic Dictionary of Biblical Greek (SDBG)\",\n",
    "    \"frame\": \"Frames of verbs, refers to the arguments of the verb\",\n",
    "    \"gender\": \"Grammatical gender values\",\n",
    "    \"gloss\": \"SIL data, not Berean\",\n",
    "    \"lemma\": \"Form of the word as it appears in a dictionary.\",\n",
    "    \"ln\": \"Short for Louw-Nida, representing the semantic domain entry in Johannes P. Louw and Eugene Albert Nida, Greek-English Lexicon of the New Testament: Based on Semantic Domains (New York: United Bible Societies, 1996).\",\n",
    "    \"mood\": \"Grammatical mood\",\n",
    "    \"morph\": \"Morphological parsing codes\",\n",
    "    \"normalized\": \"The normalized form of the token (i.e., no trailing or leading punctuation or accent shifting depending on context)\",\n",
    "    \"number\": \"Grammatical number\",\n",
    "    \"person\": \"Grammatical person\",\n",
    "    \"ref\": \"Verse!word reference to this edition of the Nestle1904 text by USFM id\",\n",
    "    \"referent\": \"The xml:id of the node to which a pronoun (i.e., 'he') refers. Note that some of these IDs are not word IDs but rather phrase or clause IDs.\",\n",
    "    \"role\": \"The clause-level role of the word.\",\n",
    "    \"strong\": \"Strong's number for the lemma\",\n",
    "    \"subjref\": \"The xml:id of the node that is the implied subject of a verb (for verbs without an explicit subject). Note that some of these IDs are not word IDs but rather phrase or clause IDs.\",\n",
    "    \"tense\": \"Grammatical tense form\",\n",
    "    \"text\": \"Text content associated with the ID\",\n",
    "    \"type\": \"Indicates different types of pronominals\",\n",
    "    \"voice\": \"Grammatical voice\",\n",
    "    \"xml:id\": \"XML ids occur on every word and encode the corpus ('n' for New Testament), the book (40 for Matthew), the chapter (001), verse (001), and word (001).\"\n",
    "}\n",
    "\n",
    "\n",
    "def generate_prosaic_context(word_id, selected_fields=None):\n",
    "    word_data = mg.loc[word_id].to_dict()\n",
    "    prompt = f\"{word_data['lemma']}'s \"\n",
    "\n",
    "    if not selected_fields:\n",
    "        selected_fields = list(attribute_descriptions.keys())\n",
    "\n",
    "    descriptions = []\n",
    "    for key in selected_fields:\n",
    "        value = word_data.get(key)\n",
    "        if value not in (None, 'missing', 'nan'):\n",
    "            attribute_description = attribute_descriptions.get(key)\n",
    "            descriptions.append(f\"{attribute_description} ({key}): {value}\")\n",
    "\n",
    "    prompt += \", \".join(descriptions)\n",
    "    return prompt\n",
    "\n",
    "# to generate prosaic context: prosaic_context = generate_prosaic_context(word_id)\n",
    "\n",
    "\n",
    "# to return a sentence based on the book_chapter_verse value:\n",
    "# mg[mg['book_chapter_verse'] == 'MAT 1:1'] # this will return every row for this verse\n",
    "# for row in mg[mg['book_chapter_verse'] == 'MAT 1:1'].itertuples():\n",
    "#     print(row)\n",
    "\n",
    "# create a set from mg['book_chapter_verse'].unique()\n",
    "unique_book_chapter_verse = set(mg['book_chapter_verse'].unique())\n",
    "\n",
    "verseRef = 'JHN 3:16'\n",
    "\n",
    "# def extract_text_and_gloss(verseRef):\n",
    "#     if verseRef not in unique_book_chapter_verse:\n",
    "#         return {text: 'verse not found', gloss: ''}\n",
    "#     result = {}\n",
    "#     for _, row in mg[mg['book_chapter_verse'] == verseRef].iterrows():\n",
    "#         result[row['text']] = row['gloss']\n",
    "#     return result\n",
    "\n",
    "# text_and_gloss = extract_text_and_gloss(verseRef) # to get text and gloss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some helper functions\n",
    "\n",
    "def get_contextual_data(tokenId):\n",
    "    prosaic_context = generate_prosaic_context(tokenId)\n",
    "    return prosaic_context\n",
    "\n",
    "\n",
    "def get_verse_content(verseRef, dataframe):\n",
    "    unique_book_chapter_verse = set(dataframe['book_chapter_verse'])\n",
    "    if verseRef not in unique_book_chapter_verse:\n",
    "        return []\n",
    "    matching_rows = dataframe[dataframe['book_chapter_verse'] == verseRef]\n",
    "    tokens = [{\"text\": row['text'], \"gloss\": row['gloss'],\"id\": idx}\n",
    "              for idx, row in matching_rows.iterrows()]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def answer_question(question, context):\n",
    "    input_dict = {'question': question, 'context': context}\n",
    "    answer = qa_pipeline(input_dict)\n",
    "    return answer['answer']\n",
    "\n",
    "\n",
    "def translate_text(text):\n",
    "    deu_result = deu_translator(text)[0]['translation_text']\n",
    "    spa_result = spa_translator(text)[0]['translation_text']\n",
    "    fra_result = fra_translator(text)[0]['translation_text']\n",
    "    return deu_result, spa_result, fra_result\n",
    "\n",
    "\n",
    "def gradio_get_verse_content(verseRef):\n",
    "    tokens = get_verse_content(verseRef, mg)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def gradio_wrapper(inputs, context):\n",
    "    question = inputs\n",
    "    answer = answer_question(question, context)\n",
    "    deu_translation, spa_translation, fra_translation = translate_text(answer)\n",
    "    return answer, deu_translation, spa_translation, fra_translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: add a function to get discourse features for token using Jake's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = gr.Blocks()\n",
    "\n",
    "with demo:\n",
    "    gr.Markdown(\"Flip text or image files using this demo.\")\n",
    "    with gr.Row():\n",
    "        verse_reference = gr.Textbox(lines=1, label=\"Verse Reference\", placeholder=\"Enter verse reference here (e.g. 'JHN 3:16')\", value=\"JHN 3:16\")\n",
    "        text_output = gr.Textbox(placeholder=\"Verse data will appear here\", max_lines=10)\n",
    "    get_verse_content_button = gr.Button(\"Get Verse Content\")\n",
    "\n",
    "    get_verse_content_button.click(\n",
    "        gradio_get_verse_content, inputs=verse_reference, outputs=text_output)\n",
    "\n",
    "    word_id_input = gr.Textbox(lines=1, label=\"Word ID\", placeholder=\"Enter word ID here (e.g. 'n43003016012')\", value=\"n43003016012\")\n",
    "    context_output = gr.Textbox(placeholder=\"Context will appear here\", max_lines=10)\n",
    "    \n",
    "    get_context_button = gr.Button(\"Get Context\")\n",
    "    \n",
    "    get_context_button.click(\n",
    "        get_contextual_data, inputs=word_id_input, outputs=context_output)\n",
    "    \n",
    "    question_input = gr.Textbox(lines=2, label=\"Question\", placeholder=\"Enter question here\")\n",
    "    answer_output = gr.Textbox(placeholder=\"Answer will appear here\", max_lines=10)\n",
    "    \n",
    "    get_answer_button = gr.Button(\"Get Answer\")\n",
    "    \n",
    "    get_answer_button.click(\n",
    "        gradio_wrapper, inputs=[question_input, context_output], outputs=answer_output)\n",
    "    \n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
